{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98fbe969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (0.2.58)\n",
      "Requirement already satisfied: pandas in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: textblob in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: newsapi-python in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: yahoo_fin in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: GoogleNews in c:\\users\\ayu\\stockprediction\\.venv\\lib\\site-packages (1.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement GoogleNews-v2 (from versions: none)\n",
      "ERROR: No matching distribution found for GoogleNews-v2\n"
     ]
    }
   ],
   "source": [
    "%pip install yfinance pandas numpy matplotlib seaborn nltk textblob tensorflow scikit-learn newsapi-python yahoo_fin GoogleNews GoogleNews-v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8d35189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from GoogleNews import GoogleNews\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b420e852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "stock_data = yf.download('AAPL', start='2022-01-01', end='2024-01-01')[['Close']].copy()\n",
    "stock_data = stock_data.reset_index()  # 'Date' becomes a column\n",
    "stock_data.columns = ['date', 'Close']  # Rename explicitly\n",
    "stock_data['date'] = pd.to_datetime(stock_data['date']).dt.date  # Ensure format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0344854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fetch news and calculate sentiment\n",
    "googlenews = GoogleNews(lang='en', period='30d')  # last 30 days\n",
    "googlenews.search('Apple stock')\n",
    "\n",
    "# for i in range(2, 6):\n",
    "#     googlenews.get_page(i)\n",
    "\n",
    "sentiments = []\n",
    "dates = []\n",
    "results = googlenews.results()\n",
    "\n",
    "for article in results:\n",
    "    text = article['title'] + '. ' + article.get('desc', '')\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    date_str = article.get('date', 'now')\n",
    "\n",
    "    try:\n",
    "        date_obj = datetime.datetime.strptime(date_str, '%b %d, %Y')\n",
    "    except:\n",
    "        date_obj = datetime.datetime.today()\n",
    "\n",
    "    sentiments.append(polarity)\n",
    "    dates.append(date_obj.date())\n",
    "\n",
    "sentiment_df = pd.DataFrame({'date': dates, 'sentiment': sentiments})\n",
    "sentiment_df = sentiment_df.groupby('date').mean().reset_index()\n",
    "sentiment_df['date'] = pd.to_datetime(sentiment_df['date']).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9480cca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayu\\AppData\\Local\\Temp\\ipykernel_17560\\3595295240.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged['sentiment'] = merged['sentiment'].fillna(method='ffill').fillna(0)\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(stock_data, sentiment_df, on='date', how='left')\n",
    "merged['sentiment'] = merged['sentiment'].fillna(method='ffill').fillna(0)\n",
    "merged.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c44c923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(merged[['Close', 'sentiment']])\n",
    "\n",
    "# 5. Create LSTM sequences\n",
    "def create_sequences(data, seq_len=60):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(seq_len, len(data)):\n",
    "        x.append(data[i-seq_len:i])\n",
    "        y.append(data[i, 0])  # Predicting 'Close'\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x, y = create_sequences(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f6d095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * len(x))\n",
    "x_train, y_train = x[:split], y[:split]\n",
    "x_test, y_test = x[split:], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "029ba672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayu\\StockPrediction\\.venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.1874\n",
      "Epoch 2/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0279\n",
      "Epoch 3/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0164\n",
      "Epoch 4/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0117\n",
      "Epoch 5/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0115\n",
      "Epoch 6/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0094\n",
      "Epoch 7/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089\n",
      "Epoch 8/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0081\n",
      "Epoch 9/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0076\n",
      "Epoch 10/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0092\n",
      "Epoch 11/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0077\n",
      "Epoch 12/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0084\n",
      "Epoch 13/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073\n",
      "Epoch 14/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0080\n",
      "Epoch 15/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0077\n",
      "Epoch 16/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065\n",
      "Epoch 17/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070\n",
      "Epoch 18/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0067\n",
      "Epoch 19/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0074\n",
      "Epoch 20/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c992bd4a30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. LSTM model using price + sentiment\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21091528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (89,1) doesn't match the broadcast shape (89,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m real \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(y_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\ayu\\StockPrediction\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:581\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    571\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    573\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    574\u001b[0m     X,\n\u001b[0;32m    575\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 581\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    582\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (89,1) doesn't match the broadcast shape (89,2)"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "real = scaler.inverse_transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eeff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(real, color='blue', label='Actual Price')\n",
    "plt.plot(predictions, color='red', label='Predicted Price')\n",
    "plt.legend()\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c436b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = np.concatenate((scaled_data, sentiment_array), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b5d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
